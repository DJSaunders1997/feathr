{"cells":[{"cell_type":"markdown","source":["# Feathr Feature Store on Azure Demo Notebook\n\nThis notebook illustrates the use of Feature Store to create a model that predicts NYC Taxi fares. It includes these steps:\n\n\nThis tutorial demonstrates the key capabilities of Feathr, including:\n\n1. Install and set up Feathr with Azure\n2. Create shareable features with Feathr feature definition configs.\n3. Create a training dataset via point-in-time feature join.\n4. Compute and write features.\n5. Train a model using these features to predict fares.\n6. Materialize feature value to online store.\n7. Fetch feature value in real-time from online store for online scoring.\n\nIn this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The feature flow is as below:\n\n![Feature Flow](https://github.com/linkedin/feathr/blob/main/docs/images/feature_flow.png?raw=true)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"384e5e16-7213-4186-9d04-09d03b155534"}}},{"cell_type":"markdown","source":["## Prerequisite: Use Quick Start Template to Provision Azure Resources\n\nFeathr has native cloud integration. To use Feathr on Azure, you only need three steps:\n\n- Get the `Principal ID` of your account by running `az ad signed-in-user show --query objectId -o tsv` in the link below (Select \"Bash\" if asked), and write down that value (something like `b65ef2e0-42b8-44a7-9b55-abbccddeefff`). Think this ID as something representing you when accessing Azure, and it will be used to grant permissions in the next step in the UI.\n\n[Launch Cloud Shell](https://shell.azure.com/bash)\n\n- Click the button below to deploy a minimal set of Feathr resources for demo purpose. You will need to fill in the `Principal ID` and `Resource Prefix`. You will need \"Owner\" permission of the selected subscription.\n\n[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Flinkedin%2Ffeathr%2Fmain%2Fdocs%2Fhow-to-guides%2Fazure_resource_provision.json)\n\n- Run the cells below.\n\nAnd the architecture is as below. In the above template, we are using Synapse as Spark provider, use Azure Data Lake Gen2 as offline store, and use Redis as online store, Azure Purview (Apache Atlas compatible) as feature reigstry. \n\n\n![Architecture](https://github.com/linkedin/feathr/blob/main/docs/images/architecture.png?raw=true)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fb39d5a-5cca-4f33-b523-a5dbd9367b6b"}}},{"cell_type":"code","source":["! pip install feathr"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f00b9d0b-94d1-418f-89b9-25bbacb8b068"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: feathr in /databricks/python3/lib/python3.8/site-packages (0.3.2)\r\nRequirement already satisfied: py4j in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.10.9.3)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.64.0)\r\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (from feathr) (6.0)\r\nRequirement already satisfied: pyarrow in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.0.0)\r\nRequirement already satisfied: pandavro in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.6.0)\r\nRequirement already satisfied: python-snappy in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.6.1)\r\nRequirement already satisfied: Jinja2 in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.11.3)\r\nRequirement already satisfied: azure-keyvault-secrets in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.4.0)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.25.1)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.2.4)\r\nRequirement already satisfied: graphlib-backport in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.0.3)\r\nRequirement already satisfied: loguru in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.6.0)\r\nRequirement already satisfied: google&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (3.0.0)\r\nRequirement already satisfied: azure-storage-file-datalake&gt;=12.5.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (12.6.0)\r\nRequirement already satisfied: Click in /databricks/python3/lib/python3.8/site-packages (from feathr) (8.1.2)\r\nRequirement already satisfied: pyspark&gt;=3.1.2 in /databricks/python3/lib/python3.8/site-packages (from feathr) (3.2.1)\r\nRequirement already satisfied: redis in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.2.2)\r\nRequirement already satisfied: pyhocon in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.3.59)\r\nRequirement already satisfied: azure-identity in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.9.0)\r\nRequirement already satisfied: deltalake in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.5.6)\r\nRequirement already satisfied: pyapacheatlas in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.11.0)\r\nRequirement already satisfied: azure-synapse-spark in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.7.0)\r\nRequirement already satisfied: google-api-python-client&gt;=2.41.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.45.0)\r\nRequirement already satisfied: azure-storage-blob&lt;13.0.0,&gt;=12.10.0 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (12.11.0)\r\nRequirement already satisfied: azure-core&lt;2.0.0,&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.23.1)\r\nRequirement already satisfied: msrest&gt;=0.6.21 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (0.6.21)\r\nRequirement already satisfied: typing-extensions&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from azure-core&lt;2.0.0,&gt;=1.15.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (4.2.0)\r\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core&lt;2.0.0,&gt;=1.15.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.15.0)\r\nRequirement already satisfied: cryptography&gt;=2.1.4 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (36.0.2)\r\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.14.5)\r\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (2.20)\r\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from google&gt;=3.0.0-&gt;feathr) (4.11.1)\r\nRequirement already satisfied: httplib2&lt;1dev,&gt;=0.15.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (0.20.4)\r\nRequirement already satisfied: google-auth&lt;3.0.0dev,&gt;=1.16.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (2.6.5)\r\nRequirement already satisfied: google-auth-httplib2&gt;=0.1.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (0.1.0)\r\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (2.7.2)\r\nRequirement already satisfied: uritemplate&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (4.1.1)\r\nRequirement already satisfied: googleapis-common-protos&lt;2.0dev,&gt;=1.52.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (1.56.0)\r\nRequirement already satisfied: protobuf&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (3.17.2)\r\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (0.2.8)\r\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (4.8)\r\nRequirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (5.0.0)\r\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,&lt;4,&gt;=2.4.2 in /databricks/python3/lib/python3.8/site-packages (from httplib2&lt;1dev,&gt;=0.15.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (2.4.7)\r\nRequirement already satisfied: isodate&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (0.6.1)\r\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (2020.12.5)\r\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.3.1)\r\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (0.4.8)\r\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (4.0.0)\r\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (1.25.11)\r\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (2.10)\r\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (3.2.0)\r\nRequirement already satisfied: msal&lt;2.0.0,&gt;=1.12.0 in /databricks/python3/lib/python3.8/site-packages (from azure-identity-&gt;feathr) (1.17.0)\r\nRequirement already satisfied: msal-extensions~=0.3.0 in /databricks/python3/lib/python3.8/site-packages (from azure-identity-&gt;feathr) (0.3.1)\r\nRequirement already satisfied: PyJWT[crypto]&lt;3,&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from msal&lt;2.0.0,&gt;=1.12.0-&gt;azure-identity-&gt;feathr) (2.3.0)\r\nRequirement already satisfied: portalocker&lt;3,&gt;=1.0 in /databricks/python3/lib/python3.8/site-packages (from msal-extensions~=0.3.0-&gt;azure-identity-&gt;feathr) (2.4.0)\r\nRequirement already satisfied: azure-common~=1.1 in /databricks/python3/lib/python3.8/site-packages (from azure-keyvault-secrets-&gt;feathr) (1.1.28)\r\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4-&gt;google&gt;=3.0.0-&gt;feathr) (2.3.2.post1)\r\nRequirement already satisfied: numpy&gt;=1.16.6 in /databricks/python3/lib/python3.8/site-packages (from pyarrow-&gt;feathr) (1.19.2)\r\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from Jinja2-&gt;feathr) (1.1.1)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;feathr) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;feathr) (2.8.1)\r\nRequirement already satisfied: fastavro&gt;=0.14.11 in /databricks/python3/lib/python3.8/site-packages (from pandavro-&gt;feathr) (1.4.10)\r\nRequirement already satisfied: openpyxl&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from pyapacheatlas-&gt;feathr) (3.0.9)\r\nRequirement already satisfied: et-xmlfile in /databricks/python3/lib/python3.8/site-packages (from openpyxl&gt;=3.0-&gt;pyapacheatlas-&gt;feathr) (1.1.0)\r\nRequirement already satisfied: packaging&gt;=20.4 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (20.9)\r\nRequirement already satisfied: deprecated&gt;=1.2.3 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (1.2.13)\r\nRequirement already satisfied: async-timeout&gt;=4.0.2 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (4.0.2)\r\nRequirement already satisfied: wrapt&lt;2,&gt;=1.10 in /databricks/python3/lib/python3.8/site-packages (from deprecated&gt;=1.2.3-&gt;redis-&gt;feathr) (1.14.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: feathr in /databricks/python3/lib/python3.8/site-packages (0.3.2)\r\nRequirement already satisfied: py4j in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.10.9.3)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.64.0)\r\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.8/site-packages (from feathr) (6.0)\r\nRequirement already satisfied: pyarrow in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.0.0)\r\nRequirement already satisfied: pandavro in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.6.0)\r\nRequirement already satisfied: python-snappy in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.6.1)\r\nRequirement already satisfied: Jinja2 in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.11.3)\r\nRequirement already satisfied: azure-keyvault-secrets in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.4.0)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.25.1)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.2.4)\r\nRequirement already satisfied: graphlib-backport in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.0.3)\r\nRequirement already satisfied: loguru in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.6.0)\r\nRequirement already satisfied: google&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (3.0.0)\r\nRequirement already satisfied: azure-storage-file-datalake&gt;=12.5.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (12.6.0)\r\nRequirement already satisfied: Click in /databricks/python3/lib/python3.8/site-packages (from feathr) (8.1.2)\r\nRequirement already satisfied: pyspark&gt;=3.1.2 in /databricks/python3/lib/python3.8/site-packages (from feathr) (3.2.1)\r\nRequirement already satisfied: redis in /databricks/python3/lib/python3.8/site-packages (from feathr) (4.2.2)\r\nRequirement already satisfied: pyhocon in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.3.59)\r\nRequirement already satisfied: azure-identity in /databricks/python3/lib/python3.8/site-packages (from feathr) (1.9.0)\r\nRequirement already satisfied: deltalake in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.5.6)\r\nRequirement already satisfied: pyapacheatlas in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.11.0)\r\nRequirement already satisfied: azure-synapse-spark in /databricks/python3/lib/python3.8/site-packages (from feathr) (0.7.0)\r\nRequirement already satisfied: google-api-python-client&gt;=2.41.0 in /databricks/python3/lib/python3.8/site-packages (from feathr) (2.45.0)\r\nRequirement already satisfied: azure-storage-blob&lt;13.0.0,&gt;=12.10.0 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (12.11.0)\r\nRequirement already satisfied: azure-core&lt;2.0.0,&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.23.1)\r\nRequirement already satisfied: msrest&gt;=0.6.21 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (0.6.21)\r\nRequirement already satisfied: typing-extensions&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from azure-core&lt;2.0.0,&gt;=1.15.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (4.2.0)\r\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core&lt;2.0.0,&gt;=1.15.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.15.0)\r\nRequirement already satisfied: cryptography&gt;=2.1.4 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (36.0.2)\r\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.14.5)\r\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (2.20)\r\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from google&gt;=3.0.0-&gt;feathr) (4.11.1)\r\nRequirement already satisfied: httplib2&lt;1dev,&gt;=0.15.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (0.20.4)\r\nRequirement already satisfied: google-auth&lt;3.0.0dev,&gt;=1.16.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (2.6.5)\r\nRequirement already satisfied: google-auth-httplib2&gt;=0.1.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (0.1.0)\r\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (2.7.2)\r\nRequirement already satisfied: uritemplate&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from google-api-python-client&gt;=2.41.0-&gt;feathr) (4.1.1)\r\nRequirement already satisfied: googleapis-common-protos&lt;2.0dev,&gt;=1.52.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (1.56.0)\r\nRequirement already satisfied: protobuf&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (3.17.2)\r\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (0.2.8)\r\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (4.8)\r\nRequirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (5.0.0)\r\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,&lt;4,&gt;=2.4.2 in /databricks/python3/lib/python3.8/site-packages (from httplib2&lt;1dev,&gt;=0.15.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (2.4.7)\r\nRequirement already satisfied: isodate&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (0.6.1)\r\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (2020.12.5)\r\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (1.3.1)\r\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3.0.0dev,&gt;=1.16.0-&gt;google-api-python-client&gt;=2.41.0-&gt;feathr) (0.4.8)\r\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (4.0.0)\r\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (1.25.11)\r\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;feathr) (2.10)\r\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.21-&gt;azure-storage-file-datalake&gt;=12.5.0-&gt;feathr) (3.2.0)\r\nRequirement already satisfied: msal&lt;2.0.0,&gt;=1.12.0 in /databricks/python3/lib/python3.8/site-packages (from azure-identity-&gt;feathr) (1.17.0)\r\nRequirement already satisfied: msal-extensions~=0.3.0 in /databricks/python3/lib/python3.8/site-packages (from azure-identity-&gt;feathr) (0.3.1)\r\nRequirement already satisfied: PyJWT[crypto]&lt;3,&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from msal&lt;2.0.0,&gt;=1.12.0-&gt;azure-identity-&gt;feathr) (2.3.0)\r\nRequirement already satisfied: portalocker&lt;3,&gt;=1.0 in /databricks/python3/lib/python3.8/site-packages (from msal-extensions~=0.3.0-&gt;azure-identity-&gt;feathr) (2.4.0)\r\nRequirement already satisfied: azure-common~=1.1 in /databricks/python3/lib/python3.8/site-packages (from azure-keyvault-secrets-&gt;feathr) (1.1.28)\r\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4-&gt;google&gt;=3.0.0-&gt;feathr) (2.3.2.post1)\r\nRequirement already satisfied: numpy&gt;=1.16.6 in /databricks/python3/lib/python3.8/site-packages (from pyarrow-&gt;feathr) (1.19.2)\r\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from Jinja2-&gt;feathr) (1.1.1)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;feathr) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;feathr) (2.8.1)\r\nRequirement already satisfied: fastavro&gt;=0.14.11 in /databricks/python3/lib/python3.8/site-packages (from pandavro-&gt;feathr) (1.4.10)\r\nRequirement already satisfied: openpyxl&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from pyapacheatlas-&gt;feathr) (3.0.9)\r\nRequirement already satisfied: et-xmlfile in /databricks/python3/lib/python3.8/site-packages (from openpyxl&gt;=3.0-&gt;pyapacheatlas-&gt;feathr) (1.1.0)\r\nRequirement already satisfied: packaging&gt;=20.4 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (20.9)\r\nRequirement already satisfied: deprecated&gt;=1.2.3 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (1.2.13)\r\nRequirement already satisfied: async-timeout&gt;=4.0.2 in /databricks/python3/lib/python3.8/site-packages (from redis-&gt;feathr) (4.0.2)\r\nRequirement already satisfied: wrapt&lt;2,&gt;=1.10 in /databricks/python3/lib/python3.8/site-packages (from deprecated&gt;=1.2.3-&gt;redis-&gt;feathr) (1.14.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["! pip install pandavro scikit-learn "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29b02824-9050-4f2f-b726-d03a92b2b43a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: pandavro in /databricks/python3/lib/python3.8/site-packages (1.6.0)\r\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\r\nRequirement already satisfied: pandas&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.2.4)\r\nRequirement already satisfied: fastavro&gt;=0.14.11 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.4.10)\r\nRequirement already satisfied: six&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.15.0)\r\nRequirement already satisfied: numpy&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.19.2)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.1.5-&gt;pandavro) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.1.5-&gt;pandavro) (2.8.1)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\r\nRequirement already satisfied: scipy&gt;=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: pandavro in /databricks/python3/lib/python3.8/site-packages (1.6.0)\r\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\r\nRequirement already satisfied: pandas&gt;=1.1.5 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.2.4)\r\nRequirement already satisfied: fastavro&gt;=0.14.11 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.4.10)\r\nRequirement already satisfied: six&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.15.0)\r\nRequirement already satisfied: numpy&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from pandavro) (1.19.2)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.1.5-&gt;pandavro) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.1.5-&gt;pandavro) (2.8.1)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\r\nRequirement already satisfied: scipy&gt;=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Login to Azure with a device code (You will see instructions in the output):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e04eebc-1943-4fbf-9be8-5bc552c23e7d"}}},{"cell_type":"code","source":["import glob\nimport os\nimport tempfile\nfrom datetime import datetime, timedelta\nfrom math import sqrt\n\nimport pandas as pd\nimport pandavro as pdx\nfrom feathr import FeathrClient\nfrom feathr import BOOLEAN, FLOAT, INT32, ValueType\nfrom feathr import Feature, DerivedFeature, FeatureAnchor\nfrom feathr import BackfillTime, MaterializationSettings\nfrom feathr import FeatureQuery, ObservationSettings\nfrom feathr import RedisSink\nfrom feathr import INPUT_CONTEXT, HdfsSource\nfrom feathr import WindowAggTransformation\nfrom feathr import TypedKey\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom azure.identity import DefaultAzureCredential\nfrom azure.keyvault.secrets import SecretClient\nimport json\nimport requests"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80223a02-631c-40c8-91b3-a037249ffff9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Get all the required credentials from Azure KeyValut"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41d3648a-9bc9-40dc-90da-bc82b21ef9b3"}}},{"cell_type":"code","source":["# Get current databricks notebook context\nctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\nhost_name = ctx.tags().get(\"browserHostName\").get()\nhost_token = ctx.apiToken().get()\ncluster_id = ctx.tags().get(\"clusterId\").get()\n\n# Get redis credentials; This is to parse Redis connection string.\nredis_port=\"\"\nredis_host=\"\"\nredis_password=\"\"\nredis_ssl=\"\"\n\n# Set the resource link\nos.environ['online_store__redis__host'] = redis_host\nos.environ['online_store__redis__port'] = redis_port\nos.environ['online_store__redis__ssl_enabled'] = redis_ssl\nos.environ['REDIS_PASSWORD']=redis_password\n\n\nfeathr_runtime_location = \"https://azurefeathrstorage.blob.core.windows.net/public/feathr-assembly-LATEST.jar\"\n\ndatabricks_config = {'run_name':'','existing_cluster_id':cluster_id,'libraries':[{'jar':''}],'spark_jar_task':{'main_class_name':'','parameters':['']}}\nos.environ['spark_config__databricks__workspace_instance_url'] = \"https://\" + host_name\nos.environ['spark_config__databricks__config_template']='{\"run_name\":\"FEATHR_FILL_IN\",\"new_cluster\":{\"spark_version\":\"10.4.x-scala2.12\",\"node_type_id\":\"Standard_D3_v2\",\"num_workers\":2,\"spark_conf\":{\"FEATHR_FILL_IN\":\"FEATHR_FILL_IN\"}},\"libraries\":[{\"jar\":\"FEATHR_FILL_IN\"}],\"spark_jar_task\":{\"main_class_name\":\"FEATHR_FILL_IN\",\"parameters\":[\"FEATHR_FILL_IN\"]}}'\nos.environ['spark_config__databricks__work_dir']='dbfs:/feathr_getting_started'\nos.environ['spark_config__databricks__feathr_runtime_location']=feathr_runtime_location\nos.environ['project_config__project_name']='feathr_getting_started'\nos.environ['DATABRICKS_WORKSPACE_TOKEN_VALUE'] = host_token"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"331753d6-1850-47b5-ad97-84b7c01d79d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Prerequisite: Configure the required environment (Don't need to update if using the above Quick Start Template)\n\nIn the first step (Provision cloud resources), you should have provisioned all the required cloud resources. If you use Feathr CLI to create a workspace, you should have a folder with a file called `feathr_config.yaml` in it with all the required configurations. Otherwise, update the configuration below.\n\nThe code below will write this configuration string to a temporary location and load it to Feathr. Please still refer to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08bc3b7e-bbf5-4e3a-9978-fe1aef8c1aee"}}},{"cell_type":"code","source":["import tempfile\nyaml_config = \"\"\"\n# Please refer to https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\napi_version: 1\nproject_config:\n  project_name: 'feathr_getting_started2'\n  required_environment_variables:\n    - 'REDIS_PASSWORD'\n    - 'AZURE_CLIENT_ID'\n    - 'AZURE_TENANT_ID'\n    - 'AZURE_CLIENT_SECRET'\noffline_store:\n  adls:\n    adls_enabled: true\n  wasb:\n    wasb_enabled: true\n  s3:\n    s3_enabled: false\n    s3_endpoint: 's3.amazonaws.com'\n  jdbc:\n    jdbc_enabled: false\n    jdbc_database: 'feathrtestdb'\n    jdbc_table: 'feathrtesttable'\n  snowflake:\n    url: \"dqllago-ol19457.snowflakecomputing.com\"\n    user: \"feathrintegration\"\n    role: \"ACCOUNTADMIN\"\nspark_config:\n  # choice for spark runtime. Currently support: azure_synapse, databricks\n  # The `databricks` configs will be ignored if `azure_synapse` is set and vice versa.\n  spark_cluster: \"databricks\"\n  spark_result_output_parts: \"1\"\n\nonline_store:\n  redis:\n    host: 'feathrazuretest3redis.redis.cache.windows.net'\n    port: 6380\n    ssl_enabled: True\nfeature_registry:\n  purview:\n    type_system_initialization: true\n    purview_name: 'feathrazuretest3-purview1'\n    delimiter: '__'\n\"\"\"\ntmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\nwith open(tmp.name, \"w\") as text_file:\n    text_file.write(yaml_config)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cd64e3a-376c-48e6-ba41-5197f3591d48"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Setup necessary environment variables (Skip if using the above Quick Start Template)\n\nYou should setup the environment variables in order to run this sample. More environment variables can be set by referring to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It also has more explanations on the meaning of each variable."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72e1faf7-f442-4ccb-a2d1-609feb0a3481"}}},{"cell_type":"code","source":["# os.environ['REDIS_PASSWORD'] = ''\n# os.environ['AZURE_CLIENT_ID'] = ''\n# os.environ['AZURE_TENANT_ID'] = ''\n# os.environ['AZURE_CLIENT_SECRET'] = ''\n\n# # Optional envs if you are using different runtimes\n# os.environ['DATABRICKS_WORKSPACE_TOKEN_VALUE'] = ''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce6fddb4-7ada-4b2d-8657-ebe37b735637"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Initialize Feathr Client"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fef7f2f-df19-4f53-90a5-ff7999ed983d"}}},{"cell_type":"code","source":["client = FeathrClient(config_path=tmp.name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9713a2df-c7b2-4562-88b0-b7acce3cc43a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2022-04-20 04:51:15.729 | INFO     | feathr._envvariableutil:get_environment_variable:61 - REDIS_PASSWORD is not set in the environment variables.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2022-04-20 04:51:15.729 | INFO     | feathr._envvariableutil:get_environment_variable:61 - REDIS_PASSWORD is not set in the environment variables.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## View the data\n\nIn this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The data is as below"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3b64bda-d42c-4a64-b976-0fb604cf38c5"}}},{"cell_type":"code","source":["import pandas as pd\npd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/green_tripdata_2020-04_with_index.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4ccd7b3-298a-4e5a-8eec-b7e309db393e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\nOut[8]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\nOut[8]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:44:02</td>\n      <td>2020-04-01 00:52:23</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>42</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>1.68</td>\n      <td>8.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>9.30</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:24:39</td>\n      <td>2020-04-01 00:33:06</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>247</td>\n      <td>2.0</td>\n      <td>1.94</td>\n      <td>9.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>10.30</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:45:06</td>\n      <td>2020-04-01 00:51:13</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>243</td>\n      <td>3.0</td>\n      <td>1.00</td>\n      <td>6.50</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>7.80</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:45:06</td>\n      <td>2020-04-01 01:04:39</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>243</td>\n      <td>2.0</td>\n      <td>2.81</td>\n      <td>12.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>13.30</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:00:23</td>\n      <td>2020-04-01 00:16:13</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>169</td>\n      <td>1.0</td>\n      <td>6.79</td>\n      <td>21.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>22.30</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35607</th>\n      <td>35607</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:29:00</td>\n      <td>2020-04-30 23:57:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>147</td>\n      <td>NaN</td>\n      <td>11.41</td>\n      <td>35.82</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.12</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>42.24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35608</th>\n      <td>35608</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:11:00</td>\n      <td>2020-04-30 23:47:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>188</td>\n      <td>230</td>\n      <td>NaN</td>\n      <td>11.17</td>\n      <td>35.45</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>38.50</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35609</th>\n      <td>35609</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:18:00</td>\n      <td>2020-04-30 23:46:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205</td>\n      <td>37</td>\n      <td>NaN</td>\n      <td>14.37</td>\n      <td>34.54</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>34.84</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35610</th>\n      <td>35610</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:55:00</td>\n      <td>2020-05-01 00:10:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>188</td>\n      <td>NaN</td>\n      <td>4.25</td>\n      <td>16.72</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>17.02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35611</th>\n      <td>35611</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:01:00</td>\n      <td>2020-04-30 23:02:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>185</td>\n      <td>185</td>\n      <td>NaN</td>\n      <td>0.01</td>\n      <td>23.17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>23.47</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>35612 rows × 21 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:44:02</td>\n      <td>2020-04-01 00:52:23</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>42</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>1.68</td>\n      <td>8.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>9.30</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:24:39</td>\n      <td>2020-04-01 00:33:06</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>247</td>\n      <td>2.0</td>\n      <td>1.94</td>\n      <td>9.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>10.30</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:45:06</td>\n      <td>2020-04-01 00:51:13</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>243</td>\n      <td>3.0</td>\n      <td>1.00</td>\n      <td>6.50</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>7.80</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:45:06</td>\n      <td>2020-04-01 01:04:39</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>244</td>\n      <td>243</td>\n      <td>2.0</td>\n      <td>2.81</td>\n      <td>12.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>13.30</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2020-04-01 00:00:23</td>\n      <td>2020-04-01 00:16:13</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>169</td>\n      <td>1.0</td>\n      <td>6.79</td>\n      <td>21.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>22.30</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35607</th>\n      <td>35607</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:29:00</td>\n      <td>2020-04-30 23:57:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>147</td>\n      <td>NaN</td>\n      <td>11.41</td>\n      <td>35.82</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.12</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>42.24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35608</th>\n      <td>35608</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:11:00</td>\n      <td>2020-04-30 23:47:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>188</td>\n      <td>230</td>\n      <td>NaN</td>\n      <td>11.17</td>\n      <td>35.45</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>38.50</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35609</th>\n      <td>35609</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:18:00</td>\n      <td>2020-04-30 23:46:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205</td>\n      <td>37</td>\n      <td>NaN</td>\n      <td>14.37</td>\n      <td>34.54</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>34.84</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35610</th>\n      <td>35610</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:55:00</td>\n      <td>2020-05-01 00:10:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>188</td>\n      <td>NaN</td>\n      <td>4.25</td>\n      <td>16.72</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>17.02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35611</th>\n      <td>35611</td>\n      <td>NaN</td>\n      <td>2020-04-30 23:01:00</td>\n      <td>2020-04-30 23:02:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>185</td>\n      <td>185</td>\n      <td>NaN</td>\n      <td>0.01</td>\n      <td>23.17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>23.47</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>35612 rows × 21 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Defining Features with Feathr\n\nIn Feathr, a feature is viewed as a function, mapping from entity id or key, and timestamp to a feature value. For more details on feature definition, please refer to the [Feathr Feature Definition Guide](https://github.com/linkedin/feathr/blob/main/docs/concepts/feature-definition.md)\n\n\n1. The typed key (a.k.a. entity id) identifies the subject of feature, e.g. a user id, 123.\n2. The feature name is the aspect of the entity that the feature is indicating, e.g. the age of the user.\n3. The feature value is the actual value of that aspect at a particular time, e.g. the value is 30 at year 2022."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7430c942-64e5-4b70-b823-16ce1d1b3cee"}}},{"cell_type":"markdown","source":["Note that, in some cases, such as features defined on top of request data, may have no entity key or timestamp.\nIt is merely a function/transformation executing against request data at runtime.\nFor example, the day of week of the request, which is calculated by converting the request UNIX timestamp."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16420730-582e-4e11-a343-efc0ddd35108"}}},{"cell_type":"markdown","source":["### Define Sources Section with UDFs\nA feature source is needed for anchored features that describes the raw data in which the feature values are computed from. See the python documentation to get the details on each input column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"728d2d5f-c11f-4941-bdc5-48507f5749f1"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession, DataFrame\ndef feathr_udf_day_calc(df: DataFrame) -> DataFrame:\n    from pyspark.sql.functions import dayofweek, dayofyear, col\n    df = df.withColumn(\"fare_amount_cents\", col(\"fare_amount\")*100)\n    return df\n\nbatch_source = HdfsSource(name=\"nycTaxiBatchSource\",\n                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\",\n                          event_timestamp_column=\"lpep_dropoff_datetime\",\n                          preprocessing=feathr_udf_day_calc,\n                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cc59a0e-a41b-480e-a84e-ca5443d63143"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Define Anchors and Features\nA feature is called an anchored feature when the feature is directly extracted from the source data, rather than computed on top of other features. The latter case is called derived feature."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46f863c4-bb81-434a-a448-6b585031a221"}}},{"cell_type":"code","source":["f_trip_distance = Feature(name=\"f_trip_distance\",\n                          feature_type=FLOAT, transform=\"trip_distance\")\n\nfeatures = [\n    f_trip_distance,\n    Feature(name=\"f_is_long_trip_distance\",\n            feature_type=BOOLEAN,\n            transform=\"cast_float(trip_distance)>30\"),\n    Feature(name=\"f_day_of_week\",\n            feature_type=INT32,\n            transform=\"dayofweek(lpep_dropoff_datetime)\"),\n]\n\nrequest_anchor = FeatureAnchor(name=\"request_features\",\n                               source=INPUT_CONTEXT,\n                               features=features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a373ecbe-a040-4cd3-9d87-0d5f4c5ba553"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Window aggregation features\n\nFor window aggregation features, see the supported fields below:\n\nNote that the `agg_func` should be any of these:\n\n| Aggregation Type | Input Type | Description |\n| --- | --- | --- |\n|SUM, COUNT, MAX, MIN, AVG\t|Numeric|Applies the the numerical operation on the numeric inputs. |\n|MAX_POOLING, MIN_POOLING, AVG_POOLING\t| Numeric Vector | Applies the max/min/avg operation on a per entry bassis for a given a collection of numbers.|\n|LATEST| Any |Returns the latest not-null values from within the defined time window |\n\n\nAfter you have defined features and sources, bring them together to build an anchor:\n\n\nNote that if the data source is from the observation data, the `source` section should be `INPUT_CONTEXT` to indicate the source of those defined anchors."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"149f85e2-fa3c-4895-b0c5-de5543ca9b6d"}}},{"cell_type":"code","source":["location_id = TypedKey(key_column=\"DOLocationID\",\n                       key_column_type=ValueType.INT32,\n                       description=\"location id in NYC\",\n                       full_name=\"nyc_taxi.location_id\")\nagg_features = [Feature(name=\"f_location_avg_fare\",\n                        key=location_id,\n                        feature_type=FLOAT,\n                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n                                                          agg_func=\"AVG\",\n                                                          window=\"90d\")),\n                Feature(name=\"f_location_max_fare\",\n                        key=location_id,\n                        feature_type=FLOAT,\n                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n                                                          agg_func=\"MAX\",\n                                                          window=\"90d\")),\n                Feature(name=\"f_location_total_fare_cents\",\n                        key=location_id,\n                        feature_type=FLOAT,\n                        transform=WindowAggTransformation(agg_expr=\"fare_amount_cents\",\n                                                          agg_func=\"SUM\",\n                                                          window=\"90d\")),\n                ]\n\nagg_anchor = FeatureAnchor(name=\"aggregationFeatures\",\n                           source=batch_source,\n                           features=agg_features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05633bc3-9118-449b-9562-45fc437576c2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Derived Features Section\nDerived features are the features that are computed from other features. They could be computed from anchored features, or other derived features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2ecaca9-057e-4b36-811f-320f66f753ed"}}},{"cell_type":"code","source":["\nf_trip_distance_rounded = DerivedFeature(name=\"f_trip_distance_rounded\",\n                                     feature_type=INT32,\n                                     input_features=[f_trip_distance],\n                                     transform=\"f_trip_distance * 10\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"270fb11e-8a71-404f-9639-ad29d8e6a2c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And then we need to build those features so that it can be consumed later. Note that we have to build both the \"anchor\" and the \"derived\" features (which is not anchored to a source)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad102c45-586d-468c-85f0-9454401ef10b"}}},{"cell_type":"code","source":["client.build_features(anchor_list=[agg_anchor, request_anchor], derived_feature_list=[\n                       f_trip_distance_rounded])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91bb5ebb-87e4-470b-b8eb-1c89b351740e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create training data using point-in-time correct feature join\n\nA training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n\nTo create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\nwhat features and how these features should be joined to the observation data. \n\nTo learn more on this topic, please refer to [Point-in-time Correctness](https://github.com/linkedin/feathr/blob/main/docs/concepts/point-in-time-join.md)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"632d5f46-f9e2-41a8-aab7-34f75206e2aa"}}},{"cell_type":"code","source":["\noutput_path = 'dbfs:/feathrazure_test.parquet'\n\n\nfeature_query = FeatureQuery(\n    feature_list=[\"f_location_avg_fare\", \"f_trip_distance_rounded\", \"f_is_long_trip_distance\", \"f_location_total_fare_cents\"], key=location_id)\nsettings = ObservationSettings(\n    observation_path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\",\n    event_timestamp_column=\"lpep_dropoff_datetime\",\n    timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\nclient.get_offline_features(observation_settings=settings,\n                            feature_query=feature_query,\n                            output_path=output_path,\n                            execution_configuratons={\"spark.feathr.outputFormat\": \"parquet\"}\n                           )\nclient.wait_job_to_finish(timeout_sec=500)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e438e6d8-162e-4aa3-b3b3-9d1f3b0d2b7f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2022-04-20 04:51:18.073 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feathr_pyspark_driver.py is uploaded to location: dbfs:/feathr_getting_started/feathr_pyspark_driver.py\n2022-04-20 04:51:18.780 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_join_conf/feature_join.conf is uploaded to location: dbfs:/feathr_getting_started/feature_join.conf\n2022-04-20 04:51:18.781 | INFO     | feathr._databricks_submission:upload_or_get_cloud_path:90 - Uploading folder /tmp/tmpwttnn5le/feature_conf/\n2022-04-20 04:51:19.368 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_anchored_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_anchored_features.conf\n2022-04-20 04:51:20.285 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_request_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_request_features.conf\n2022-04-20 04:51:20.861 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_derived_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_derived_features.conf\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_ACCESS_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_SECRET_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_ACCOUNT is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_ACCOUNT is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TABLE is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_USER is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_PASSWORD is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_DRIVER is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_AUTH_FLAG is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TOKEN is not set in the environment variables.\n2022-04-20 04:51:20.878 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_SF_PASSWORD is not set in the environment variables.\n2022-04-20 04:51:30.949 | DEBUG    | feathr._databricks_submission:upload_or_get_cloud_path:80 - https://azurefeathrstorage.blob.core.windows.net/public/feathr-assembly-LATEST.jar is downloaded and then uploaded to location: dbfs:/feathr_getting_started/feathr-assembly-LATEST.jar\n2022-04-20 04:51:30.957 | DEBUG    | feathr._databricks_submission:upload_or_get_cloud_path:84 - Skipping file dbfs:/feathr_getting_started/feathr_pyspark_driver.py as it is already in the cloud\n2022-04-20 04:51:31.464 | INFO     | feathr._databricks_submission:submit_feathr_job:172 - Feathr Job Submitted Sucessfully. View more details here: https://adb-2474129336842816.16.azuredatabricks.net/?o=2474129336842816#job/200732889873337/run/63018\n2022-04-20 04:51:31.767 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:52:01.960 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:52:32.106 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:53:02.249 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:53:32.377 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:54:02.610 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:54:32.747 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:55:02.916 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:55:33.052 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:56:03.198 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:56:33.397 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:57:03.548 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:57:33.760 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: SUCCESS\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2022-04-20 04:51:18.073 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feathr_pyspark_driver.py is uploaded to location: dbfs:/feathr_getting_started/feathr_pyspark_driver.py\n2022-04-20 04:51:18.780 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_join_conf/feature_join.conf is uploaded to location: dbfs:/feathr_getting_started/feature_join.conf\n2022-04-20 04:51:18.781 | INFO     | feathr._databricks_submission:upload_or_get_cloud_path:90 - Uploading folder /tmp/tmpwttnn5le/feature_conf/\n2022-04-20 04:51:19.368 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_anchored_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_anchored_features.conf\n2022-04-20 04:51:20.285 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_request_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_request_features.conf\n2022-04-20 04:51:20.861 | DEBUG    | feathr._databricks_submission:upload_file:113 - /tmp/tmpwttnn5le/feature_conf/auto_generated_derived_features.conf is uploaded to location: dbfs:/feathr_getting_started/auto_generated_derived_features.conf\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_ACCESS_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_SECRET_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_ACCOUNT is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_ACCOUNT is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_KEY is not set in the environment variables.\n2022-04-20 04:51:20.863 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TABLE is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_USER is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_PASSWORD is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_DRIVER is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_AUTH_FLAG is not set in the environment variables.\n2022-04-20 04:51:20.864 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TOKEN is not set in the environment variables.\n2022-04-20 04:51:20.878 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_SF_PASSWORD is not set in the environment variables.\n2022-04-20 04:51:30.949 | DEBUG    | feathr._databricks_submission:upload_or_get_cloud_path:80 - https://azurefeathrstorage.blob.core.windows.net/public/feathr-assembly-LATEST.jar is downloaded and then uploaded to location: dbfs:/feathr_getting_started/feathr-assembly-LATEST.jar\n2022-04-20 04:51:30.957 | DEBUG    | feathr._databricks_submission:upload_or_get_cloud_path:84 - Skipping file dbfs:/feathr_getting_started/feathr_pyspark_driver.py as it is already in the cloud\n2022-04-20 04:51:31.464 | INFO     | feathr._databricks_submission:submit_feathr_job:172 - Feathr Job Submitted Sucessfully. View more details here: https://adb-2474129336842816.16.azuredatabricks.net/?o=2474129336842816#job/200732889873337/run/63018\n2022-04-20 04:51:31.767 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:52:01.960 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:52:32.106 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:53:02.249 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:53:32.377 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:54:02.610 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:54:32.747 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:55:02.916 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:55:33.052 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: PENDING\n2022-04-20 04:56:03.198 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:56:33.397 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:57:03.548 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: RUNNING\n2022-04-20 04:57:33.760 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: SUCCESS\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Download the result and show the result\n\nLet's use the helper function `get_result_df` to download the result and view it:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51f078e3-3f8f-4f10-b7f1-499ac8a9ff07"}}},{"cell_type":"code","source":["from feathr.job_utils import get_result_df\ndf_res = get_result_df(client)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23c797b2-ac1a-4cf3-b0ed-c05216de3f37"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2022-04-20 05:01:25.451 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: SUCCESS\n\rDownloading result files:   0%|          | 0/148 [00:00&lt;?, ?it/s]\rDownloading result files:   1%|▏         | 2/148 [00:00&lt;00:36,  3.98it/s]\rDownloading result files:   3%|▎         | 4/148 [00:01&lt;00:48,  2.95it/s]\rDownloading result files:   3%|▎         | 5/148 [00:02&lt;01:12,  1.97it/s]\rDownloading result files:   4%|▍         | 6/148 [00:02&lt;01:19,  1.78it/s]\rDownloading result files:   5%|▍         | 7/148 [00:03&lt;01:22,  1.71it/s]\rDownloading result files:   5%|▌         | 8/148 [00:04&lt;01:17,  1.80it/s]\rDownloading result files:   6%|▌         | 9/148 [00:04&lt;01:12,  1.92it/s]\rDownloading result files:   7%|▋         | 10/148 [00:04&lt;01:11,  1.94it/s]\rDownloading result files:   7%|▋         | 11/148 [00:05&lt;01:08,  1.99it/s]\rDownloading result files:   8%|▊         | 12/148 [00:05&lt;01:06,  2.05it/s]\rDownloading result files:   9%|▉         | 13/148 [00:06&lt;01:04,  2.10it/s]\rDownloading result files:   9%|▉         | 14/148 [00:06&lt;01:09,  1.94it/s]\rDownloading result files:  10%|█         | 15/148 [00:07&lt;01:08,  1.93it/s]\rDownloading result files:  11%|█         | 16/148 [00:07&lt;01:05,  2.00it/s]\rDownloading result files:  11%|█▏        | 17/148 [00:08&lt;01:04,  2.02it/s]\rDownloading result files:  12%|█▏        | 18/148 [00:08&lt;01:04,  2.00it/s]\rDownloading result files:  13%|█▎        | 19/148 [00:09&lt;01:14,  1.74it/s]\rDownloading result files:  14%|█▎        | 20/148 [00:10&lt;01:12,  1.77it/s]\rDownloading result files:  14%|█▍        | 21/148 [00:10&lt;01:10,  1.81it/s]\rDownloading result files:  15%|█▍        | 22/148 [00:11&lt;01:07,  1.86it/s]\rDownloading result files:  16%|█▌        | 23/148 [00:11&lt;01:04,  1.93it/s]\rDownloading result files:  16%|█▌        | 24/148 [00:12&lt;01:03,  1.95it/s]\rDownloading result files:  17%|█▋        | 25/148 [00:12&lt;01:09,  1.78it/s]\rDownloading result files:  18%|█▊        | 26/148 [00:13&lt;01:05,  1.85it/s]\rDownloading result files:  18%|█▊        | 27/148 [00:13&lt;01:01,  1.96it/s]\rDownloading result files:  19%|█▉        | 28/148 [00:14&lt;00:59,  2.01it/s]\rDownloading result files:  20%|█▉        | 29/148 [00:14&lt;00:57,  2.05it/s]\rDownloading result files:  20%|██        | 30/148 [00:15&lt;00:56,  2.09it/s]\rDownloading result files:  21%|██        | 31/148 [00:15&lt;00:56,  2.07it/s]\rDownloading result files:  22%|██▏       | 32/148 [00:16&lt;00:55,  2.08it/s]\rDownloading result files:  22%|██▏       | 33/148 [00:16&lt;00:54,  2.11it/s]\rDownloading result files:  23%|██▎       | 34/148 [00:17&lt;00:53,  2.14it/s]\rDownloading result files:  24%|██▎       | 35/148 [00:17&lt;00:52,  2.14it/s]\rDownloading result files:  24%|██▍       | 36/148 [00:18&lt;00:51,  2.17it/s]\rDownloading result files:  25%|██▌       | 37/148 [00:18&lt;00:56,  1.97it/s]\rDownloading result files:  26%|██▌       | 38/148 [00:19&lt;00:54,  2.02it/s]\rDownloading result files:  26%|██▋       | 39/148 [00:19&lt;00:53,  2.05it/s]\rDownloading result files:  27%|██▋       | 40/148 [00:20&lt;01:00,  1.78it/s]\rDownloading result files:  28%|██▊       | 41/148 [00:20&lt;01:02,  1.70it/s]\rDownloading result files:  28%|██▊       | 42/148 [00:21&lt;00:59,  1.78it/s]\rDownloading result files:  29%|██▉       | 43/148 [00:21&lt;00:56,  1.86it/s]\rDownloading result files:  30%|██▉       | 44/148 [00:22&lt;00:55,  1.88it/s]\rDownloading result files:  30%|███       | 45/148 [00:22&lt;00:52,  1.95it/s]\rDownloading result files:  31%|███       | 46/148 [00:23&lt;00:52,  1.96it/s]\rDownloading result files:  32%|███▏      | 47/148 [00:23&lt;00:53,  1.90it/s]\rDownloading result files:  32%|███▏      | 48/148 [00:24&lt;00:51,  1.94it/s]\rDownloading result files:  33%|███▎      | 49/148 [00:24&lt;00:50,  1.95it/s]\rDownloading result files:  34%|███▍      | 50/148 [00:25&lt;00:49,  1.98it/s]\rDownloading result files:  34%|███▍      | 51/148 [00:25&lt;00:47,  2.04it/s]\rDownloading result files:  35%|███▌      | 52/148 [00:26&lt;00:51,  1.85it/s]\rDownloading result files:  36%|███▌      | 53/148 [00:27&lt;00:50,  1.88it/s]\rDownloading result files:  36%|███▋      | 54/148 [00:27&lt;00:48,  1.93it/s]\rDownloading result files:  37%|███▋      | 55/148 [00:28&lt;00:47,  1.97it/s]\rDownloading result files:  38%|███▊      | 56/148 [00:28&lt;00:45,  2.02it/s]\rDownloading result files:  39%|███▊      | 57/148 [00:29&lt;00:44,  2.04it/s]\rDownloading result files:  39%|███▉      | 58/148 [00:29&lt;00:42,  2.10it/s]\rDownloading result files:  40%|███▉      | 59/148 [00:29&lt;00:41,  2.13it/s]\rDownloading result files:  41%|████      | 60/148 [00:30&lt;00:40,  2.15it/s]\rDownloading result files:  41%|████      | 61/148 [00:30&lt;00:40,  2.15it/s]\rDownloading result files:  42%|████▏     | 62/148 [00:31&lt;00:40,  2.14it/s]\rDownloading result files:  43%|████▎     | 63/148 [00:31&lt;00:40,  2.09it/s]\rDownloading result files:  43%|████▎     | 64/148 [00:32&lt;00:40,  2.08it/s]\rDownloading result files:  44%|████▍     | 65/148 [00:32&lt;00:40,  2.03it/s]\rDownloading result files:  45%|████▍     | 66/148 [00:33&lt;00:40,  2.02it/s]\rDownloading result files:  45%|████▌     | 67/148 [00:33&lt;00:41,  1.95it/s]\rDownloading result files:  46%|████▌     | 68/148 [00:34&lt;00:48,  1.64it/s]\rDownloading result files:  47%|████▋     | 69/148 [00:35&lt;00:45,  1.72it/s]\rDownloading result files:  47%|████▋     | 70/148 [00:35&lt;00:45,  1.70it/s]\rDownloading result files:  48%|████▊     | 71/148 [00:36&lt;00:42,  1.79it/s]\rDownloading result files:  49%|████▊     | 72/148 [00:36&lt;00:43,  1.75it/s]\rDownloading result files:  49%|████▉     | 73/148 [00:37&lt;00:42,  1.75it/s]\rDownloading result files:  50%|█████     | 74/148 [00:38&lt;00:42,  1.75it/s]\rDownloading result files:  51%|█████     | 75/148 [00:38&lt;00:39,  1.86it/s]\rDownloading result files:  51%|█████▏    | 76/148 [00:38&lt;00:37,  1.94it/s]\rDownloading result files:  52%|█████▏    | 77/148 [00:39&lt;00:36,  1.97it/s]\rDownloading result files:  53%|█████▎    | 78/148 [00:39&lt;00:35,  1.96it/s]\rDownloading result files:  53%|█████▎    | 79/148 [00:40&lt;00:34,  2.00it/s]\rDownloading result files:  54%|█████▍    | 80/148 [00:41&lt;00:36,  1.86it/s]\rDownloading result files:  55%|█████▍    | 81/148 [00:41&lt;00:34,  1.94it/s]\rDownloading result files:  55%|█████▌    | 82/148 [00:42&lt;00:35,  1.88it/s]\rDownloading result files:  56%|█████▌    | 83/148 [00:42&lt;00:35,  1.82it/s]\rDownloading result files:  57%|█████▋    | 84/148 [00:43&lt;00:34,  1.87it/s]\rDownloading result files:  57%|█████▋    | 85/148 [00:43&lt;00:32,  1.92it/s]\rDownloading result files:  58%|█████▊    | 86/148 [00:44&lt;00:30,  2.00it/s]\rDownloading result files:  59%|█████▉    | 87/148 [00:44&lt;00:30,  2.00it/s]\rDownloading result files:  59%|█████▉    | 88/148 [00:45&lt;00:29,  2.01it/s]\rDownloading result files:  60%|██████    | 89/148 [00:45&lt;00:30,  1.95it/s]\rDownloading result files:  61%|██████    | 90/148 [00:46&lt;00:31,  1.82it/s]\rDownloading result files:  61%|██████▏   | 91/148 [00:46&lt;00:30,  1.89it/s]\rDownloading result files:  62%|██████▏   | 92/148 [00:47&lt;00:28,  1.94it/s]\rDownloading result files:  63%|██████▎   | 93/148 [00:47&lt;00:29,  1.84it/s]\rDownloading result files:  64%|██████▎   | 94/148 [00:48&lt;00:28,  1.88it/s]\rDownloading result files:  64%|██████▍   | 95/148 [00:48&lt;00:28,  1.88it/s]\rDownloading result files:  65%|██████▍   | 96/148 [00:49&lt;00:26,  1.94it/s]\rDownloading result files:  66%|██████▌   | 97/148 [00:49&lt;00:27,  1.85it/s]\rDownloading result files:  66%|██████▌   | 98/148 [00:50&lt;00:26,  1.88it/s]\rDownloading result files:  67%|██████▋   | 99/148 [00:51&lt;00:26,  1.85it/s]\rDownloading result files:  68%|██████▊   | 100/148 [00:51&lt;00:25,  1.91it/s]\rDownloading result files:  68%|██████▊   | 101/148 [00:52&lt;00:24,  1.92it/s]\rDownloading result files:  69%|██████▉   | 102/148 [00:52&lt;00:23,  1.94it/s]\rDownloading result files:  70%|██████▉   | 103/148 [00:53&lt;00:24,  1.84it/s]\rDownloading result files:  70%|███████   | 104/148 [00:53&lt;00:23,  1.87it/s]\rDownloading result files:  71%|███████   | 105/148 [00:54&lt;00:22,  1.91it/s]\rDownloading result files:  72%|███████▏  | 106/148 [00:54&lt;00:24,  1.71it/s]\rDownloading result files:  72%|███████▏  | 107/148 [00:55&lt;00:22,  1.81it/s]\rDownloading result files:  73%|███████▎  | 108/148 [00:55&lt;00:21,  1.89it/s]\rDownloading result files:  74%|███████▎  | 109/148 [00:56&lt;00:21,  1.86it/s]\rDownloading result files:  74%|███████▍  | 110/148 [00:56&lt;00:19,  1.93it/s]\rDownloading result files:  75%|███████▌  | 111/148 [00:57&lt;00:19,  1.93it/s]\rDownloading result files:  76%|███████▌  | 112/148 [00:57&lt;00:19,  1.88it/s]\rDownloading result files:  76%|███████▋  | 113/148 [00:58&lt;00:18,  1.93it/s]\rDownloading result files:  77%|███████▋  | 114/148 [00:58&lt;00:17,  1.93it/s]\rDownloading result files:  78%|███████▊  | 115/148 [00:59&lt;00:16,  1.97it/s]\rDownloading result files:  78%|███████▊  | 116/148 [01:00&lt;00:18,  1.69it/s]\rDownloading result files:  79%|███████▉  | 117/148 [01:00&lt;00:17,  1.81it/s]\rDownloading result files:  80%|███████▉  | 118/148 [01:01&lt;00:16,  1.82it/s]\rDownloading result files:  80%|████████  | 119/148 [01:01&lt;00:15,  1.85it/s]\rDownloading result files:  81%|████████  | 120/148 [01:02&lt;00:14,  1.91it/s]\rDownloading result files:  82%|████████▏ | 121/148 [01:02&lt;00:14,  1.91it/s]\rDownloading result files:  82%|████████▏ | 122/148 [01:03&lt;00:13,  1.92it/s]\rDownloading result files:  83%|████████▎ | 123/148 [01:04&lt;00:14,  1.72it/s]\rDownloading result files:  84%|████████▍ | 124/148 [01:04&lt;00:13,  1.79it/s]\rDownloading result files:  84%|████████▍ | 125/148 [01:05&lt;00:12,  1.84it/s]\rDownloading result files:  85%|████████▌ | 126/148 [01:05&lt;00:11,  1.85it/s]\rDownloading result files:  86%|████████▌ | 127/148 [01:06&lt;00:10,  1.92it/s]\rDownloading result files:  86%|████████▋ | 128/148 [01:06&lt;00:10,  1.92it/s]\rDownloading result files:  87%|████████▋ | 129/148 [01:07&lt;00:10,  1.89it/s]\rDownloading result files:  88%|████████▊ | 130/148 [01:07&lt;00:09,  1.88it/s]\rDownloading result files:  89%|████████▊ | 131/148 [01:08&lt;00:08,  1.89it/s]\rDownloading result files:  89%|████████▉ | 132/148 [01:08&lt;00:08,  1.89it/s]\rDownloading result files:  90%|████████▉ | 133/148 [01:09&lt;00:08,  1.77it/s]\rDownloading result files:  91%|█████████ | 134/148 [01:09&lt;00:07,  1.84it/s]\rDownloading result files:  91%|█████████ | 135/148 [01:10&lt;00:06,  1.86it/s]\rDownloading result files:  92%|█████████▏| 136/148 [01:10&lt;00:06,  1.95it/s]\rDownloading result files:  93%|█████████▎| 137/148 [01:11&lt;00:06,  1.80it/s]\rDownloading result files:  93%|█████████▎| 138/148 [01:12&lt;00:05,  1.81it/s]\rDownloading result files:  94%|█████████▍| 139/148 [01:12&lt;00:04,  1.89it/s]\rDownloading result files:  95%|█████████▍| 140/148 [01:13&lt;00:04,  1.91it/s]\rDownloading result files:  95%|█████████▌| 141/148 [01:13&lt;00:03,  1.97it/s]\rDownloading result files:  96%|█████████▌| 142/148 [01:13&lt;00:03,  1.98it/s]\rDownloading result files:  97%|█████████▋| 143/148 [01:14&lt;00:02,  1.94it/s]\rDownloading result files:  97%|█████████▋| 144/148 [01:15&lt;00:02,  1.97it/s]\rDownloading result files:  98%|█████████▊| 145/148 [01:15&lt;00:01,  1.91it/s]\rDownloading result files:  99%|█████████▊| 146/148 [01:16&lt;00:01,  1.79it/s]\rDownloading result files:  99%|█████████▉| 147/148 [01:16&lt;00:00,  1.88it/s]\rDownloading result files: 100%|██████████| 148/148 [01:17&lt;00:00,  1.92it/s]\rDownloading result files: 100%|██████████| 148/148 [01:17&lt;00:00,  1.92it/s]\n2022-04-20 05:02:43.535 | INFO     | feathr._databricks_submission:download_result:272 - Finish downloading files from dbfs:/feathrazure_test.parquet to /tmp/tmpg15bz4el.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2022-04-20 05:01:25.451 | DEBUG    | feathr._databricks_submission:wait_for_completion:184 - Current Spark job status: SUCCESS\n\rDownloading result files:   0%|          | 0/148 [00:00&lt;?, ?it/s]\rDownloading result files:   1%|▏         | 2/148 [00:00&lt;00:36,  3.98it/s]\rDownloading result files:   3%|▎         | 4/148 [00:01&lt;00:48,  2.95it/s]\rDownloading result files:   3%|▎         | 5/148 [00:02&lt;01:12,  1.97it/s]\rDownloading result files:   4%|▍         | 6/148 [00:02&lt;01:19,  1.78it/s]\rDownloading result files:   5%|▍         | 7/148 [00:03&lt;01:22,  1.71it/s]\rDownloading result files:   5%|▌         | 8/148 [00:04&lt;01:17,  1.80it/s]\rDownloading result files:   6%|▌         | 9/148 [00:04&lt;01:12,  1.92it/s]\rDownloading result files:   7%|▋         | 10/148 [00:04&lt;01:11,  1.94it/s]\rDownloading result files:   7%|▋         | 11/148 [00:05&lt;01:08,  1.99it/s]\rDownloading result files:   8%|▊         | 12/148 [00:05&lt;01:06,  2.05it/s]\rDownloading result files:   9%|▉         | 13/148 [00:06&lt;01:04,  2.10it/s]\rDownloading result files:   9%|▉         | 14/148 [00:06&lt;01:09,  1.94it/s]\rDownloading result files:  10%|█         | 15/148 [00:07&lt;01:08,  1.93it/s]\rDownloading result files:  11%|█         | 16/148 [00:07&lt;01:05,  2.00it/s]\rDownloading result files:  11%|█▏        | 17/148 [00:08&lt;01:04,  2.02it/s]\rDownloading result files:  12%|█▏        | 18/148 [00:08&lt;01:04,  2.00it/s]\rDownloading result files:  13%|█▎        | 19/148 [00:09&lt;01:14,  1.74it/s]\rDownloading result files:  14%|█▎        | 20/148 [00:10&lt;01:12,  1.77it/s]\rDownloading result files:  14%|█▍        | 21/148 [00:10&lt;01:10,  1.81it/s]\rDownloading result files:  15%|█▍        | 22/148 [00:11&lt;01:07,  1.86it/s]\rDownloading result files:  16%|█▌        | 23/148 [00:11&lt;01:04,  1.93it/s]\rDownloading result files:  16%|█▌        | 24/148 [00:12&lt;01:03,  1.95it/s]\rDownloading result files:  17%|█▋        | 25/148 [00:12&lt;01:09,  1.78it/s]\rDownloading result files:  18%|█▊        | 26/148 [00:13&lt;01:05,  1.85it/s]\rDownloading result files:  18%|█▊        | 27/148 [00:13&lt;01:01,  1.96it/s]\rDownloading result files:  19%|█▉        | 28/148 [00:14&lt;00:59,  2.01it/s]\rDownloading result files:  20%|█▉        | 29/148 [00:14&lt;00:57,  2.05it/s]\rDownloading result files:  20%|██        | 30/148 [00:15&lt;00:56,  2.09it/s]\rDownloading result files:  21%|██        | 31/148 [00:15&lt;00:56,  2.07it/s]\rDownloading result files:  22%|██▏       | 32/148 [00:16&lt;00:55,  2.08it/s]\rDownloading result files:  22%|██▏       | 33/148 [00:16&lt;00:54,  2.11it/s]\rDownloading result files:  23%|██▎       | 34/148 [00:17&lt;00:53,  2.14it/s]\rDownloading result files:  24%|██▎       | 35/148 [00:17&lt;00:52,  2.14it/s]\rDownloading result files:  24%|██▍       | 36/148 [00:18&lt;00:51,  2.17it/s]\rDownloading result files:  25%|██▌       | 37/148 [00:18&lt;00:56,  1.97it/s]\rDownloading result files:  26%|██▌       | 38/148 [00:19&lt;00:54,  2.02it/s]\rDownloading result files:  26%|██▋       | 39/148 [00:19&lt;00:53,  2.05it/s]\rDownloading result files:  27%|██▋       | 40/148 [00:20&lt;01:00,  1.78it/s]\rDownloading result files:  28%|██▊       | 41/148 [00:20&lt;01:02,  1.70it/s]\rDownloading result files:  28%|██▊       | 42/148 [00:21&lt;00:59,  1.78it/s]\rDownloading result files:  29%|██▉       | 43/148 [00:21&lt;00:56,  1.86it/s]\rDownloading result files:  30%|██▉       | 44/148 [00:22&lt;00:55,  1.88it/s]\rDownloading result files:  30%|███       | 45/148 [00:22&lt;00:52,  1.95it/s]\rDownloading result files:  31%|███       | 46/148 [00:23&lt;00:52,  1.96it/s]\rDownloading result files:  32%|███▏      | 47/148 [00:23&lt;00:53,  1.90it/s]\rDownloading result files:  32%|███▏      | 48/148 [00:24&lt;00:51,  1.94it/s]\rDownloading result files:  33%|███▎      | 49/148 [00:24&lt;00:50,  1.95it/s]\rDownloading result files:  34%|███▍      | 50/148 [00:25&lt;00:49,  1.98it/s]\rDownloading result files:  34%|███▍      | 51/148 [00:25&lt;00:47,  2.04it/s]\rDownloading result files:  35%|███▌      | 52/148 [00:26&lt;00:51,  1.85it/s]\rDownloading result files:  36%|███▌      | 53/148 [00:27&lt;00:50,  1.88it/s]\rDownloading result files:  36%|███▋      | 54/148 [00:27&lt;00:48,  1.93it/s]\rDownloading result files:  37%|███▋      | 55/148 [00:28&lt;00:47,  1.97it/s]\rDownloading result files:  38%|███▊      | 56/148 [00:28&lt;00:45,  2.02it/s]\rDownloading result files:  39%|███▊      | 57/148 [00:29&lt;00:44,  2.04it/s]\rDownloading result files:  39%|███▉      | 58/148 [00:29&lt;00:42,  2.10it/s]\rDownloading result files:  40%|███▉      | 59/148 [00:29&lt;00:41,  2.13it/s]\rDownloading result files:  41%|████      | 60/148 [00:30&lt;00:40,  2.15it/s]\rDownloading result files:  41%|████      | 61/148 [00:30&lt;00:40,  2.15it/s]\rDownloading result files:  42%|████▏     | 62/148 [00:31&lt;00:40,  2.14it/s]\rDownloading result files:  43%|████▎     | 63/148 [00:31&lt;00:40,  2.09it/s]\rDownloading result files:  43%|████▎     | 64/148 [00:32&lt;00:40,  2.08it/s]\rDownloading result files:  44%|████▍     | 65/148 [00:32&lt;00:40,  2.03it/s]\rDownloading result files:  45%|████▍     | 66/148 [00:33&lt;00:40,  2.02it/s]\rDownloading result files:  45%|████▌     | 67/148 [00:33&lt;00:41,  1.95it/s]\rDownloading result files:  46%|████▌     | 68/148 [00:34&lt;00:48,  1.64it/s]\rDownloading result files:  47%|████▋     | 69/148 [00:35&lt;00:45,  1.72it/s]\rDownloading result files:  47%|████▋     | 70/148 [00:35&lt;00:45,  1.70it/s]\rDownloading result files:  48%|████▊     | 71/148 [00:36&lt;00:42,  1.79it/s]\rDownloading result files:  49%|████▊     | 72/148 [00:36&lt;00:43,  1.75it/s]\rDownloading result files:  49%|████▉     | 73/148 [00:37&lt;00:42,  1.75it/s]\rDownloading result files:  50%|█████     | 74/148 [00:38&lt;00:42,  1.75it/s]\rDownloading result files:  51%|█████     | 75/148 [00:38&lt;00:39,  1.86it/s]\rDownloading result files:  51%|█████▏    | 76/148 [00:38&lt;00:37,  1.94it/s]\rDownloading result files:  52%|█████▏    | 77/148 [00:39&lt;00:36,  1.97it/s]\rDownloading result files:  53%|█████▎    | 78/148 [00:39&lt;00:35,  1.96it/s]\rDownloading result files:  53%|█████▎    | 79/148 [00:40&lt;00:34,  2.00it/s]\rDownloading result files:  54%|█████▍    | 80/148 [00:41&lt;00:36,  1.86it/s]\rDownloading result files:  55%|█████▍    | 81/148 [00:41&lt;00:34,  1.94it/s]\rDownloading result files:  55%|█████▌    | 82/148 [00:42&lt;00:35,  1.88it/s]\rDownloading result files:  56%|█████▌    | 83/148 [00:42&lt;00:35,  1.82it/s]\rDownloading result files:  57%|█████▋    | 84/148 [00:43&lt;00:34,  1.87it/s]\rDownloading result files:  57%|█████▋    | 85/148 [00:43&lt;00:32,  1.92it/s]\rDownloading result files:  58%|█████▊    | 86/148 [00:44&lt;00:30,  2.00it/s]\rDownloading result files:  59%|█████▉    | 87/148 [00:44&lt;00:30,  2.00it/s]\rDownloading result files:  59%|█████▉    | 88/148 [00:45&lt;00:29,  2.01it/s]\rDownloading result files:  60%|██████    | 89/148 [00:45&lt;00:30,  1.95it/s]\rDownloading result files:  61%|██████    | 90/148 [00:46&lt;00:31,  1.82it/s]\rDownloading result files:  61%|██████▏   | 91/148 [00:46&lt;00:30,  1.89it/s]\rDownloading result files:  62%|██████▏   | 92/148 [00:47&lt;00:28,  1.94it/s]\rDownloading result files:  63%|██████▎   | 93/148 [00:47&lt;00:29,  1.84it/s]\rDownloading result files:  64%|██████▎   | 94/148 [00:48&lt;00:28,  1.88it/s]\rDownloading result files:  64%|██████▍   | 95/148 [00:48&lt;00:28,  1.88it/s]\rDownloading result files:  65%|██████▍   | 96/148 [00:49&lt;00:26,  1.94it/s]\rDownloading result files:  66%|██████▌   | 97/148 [00:49&lt;00:27,  1.85it/s]\rDownloading result files:  66%|██████▌   | 98/148 [00:50&lt;00:26,  1.88it/s]\rDownloading result files:  67%|██████▋   | 99/148 [00:51&lt;00:26,  1.85it/s]\rDownloading result files:  68%|██████▊   | 100/148 [00:51&lt;00:25,  1.91it/s]\rDownloading result files:  68%|██████▊   | 101/148 [00:52&lt;00:24,  1.92it/s]\rDownloading result files:  69%|██████▉   | 102/148 [00:52&lt;00:23,  1.94it/s]\rDownloading result files:  70%|██████▉   | 103/148 [00:53&lt;00:24,  1.84it/s]\rDownloading result files:  70%|███████   | 104/148 [00:53&lt;00:23,  1.87it/s]\rDownloading result files:  71%|███████   | 105/148 [00:54&lt;00:22,  1.91it/s]\rDownloading result files:  72%|███████▏  | 106/148 [00:54&lt;00:24,  1.71it/s]\rDownloading result files:  72%|███████▏  | 107/148 [00:55&lt;00:22,  1.81it/s]\rDownloading result files:  73%|███████▎  | 108/148 [00:55&lt;00:21,  1.89it/s]\rDownloading result files:  74%|███████▎  | 109/148 [00:56&lt;00:21,  1.86it/s]\rDownloading result files:  74%|███████▍  | 110/148 [00:56&lt;00:19,  1.93it/s]\rDownloading result files:  75%|███████▌  | 111/148 [00:57&lt;00:19,  1.93it/s]\rDownloading result files:  76%|███████▌  | 112/148 [00:57&lt;00:19,  1.88it/s]\rDownloading result files:  76%|███████▋  | 113/148 [00:58&lt;00:18,  1.93it/s]\rDownloading result files:  77%|███████▋  | 114/148 [00:58&lt;00:17,  1.93it/s]\rDownloading result files:  78%|███████▊  | 115/148 [00:59&lt;00:16,  1.97it/s]\rDownloading result files:  78%|███████▊  | 116/148 [01:00&lt;00:18,  1.69it/s]\rDownloading result files:  79%|███████▉  | 117/148 [01:00&lt;00:17,  1.81it/s]\rDownloading result files:  80%|███████▉  | 118/148 [01:01&lt;00:16,  1.82it/s]\rDownloading result files:  80%|████████  | 119/148 [01:01&lt;00:15,  1.85it/s]\rDownloading result files:  81%|████████  | 120/148 [01:02&lt;00:14,  1.91it/s]\rDownloading result files:  82%|████████▏ | 121/148 [01:02&lt;00:14,  1.91it/s]\rDownloading result files:  82%|████████▏ | 122/148 [01:03&lt;00:13,  1.92it/s]\rDownloading result files:  83%|████████▎ | 123/148 [01:04&lt;00:14,  1.72it/s]\rDownloading result files:  84%|████████▍ | 124/148 [01:04&lt;00:13,  1.79it/s]\rDownloading result files:  84%|████████▍ | 125/148 [01:05&lt;00:12,  1.84it/s]\rDownloading result files:  85%|████████▌ | 126/148 [01:05&lt;00:11,  1.85it/s]\rDownloading result files:  86%|████████▌ | 127/148 [01:06&lt;00:10,  1.92it/s]\rDownloading result files:  86%|████████▋ | 128/148 [01:06&lt;00:10,  1.92it/s]\rDownloading result files:  87%|████████▋ | 129/148 [01:07&lt;00:10,  1.89it/s]\rDownloading result files:  88%|████████▊ | 130/148 [01:07&lt;00:09,  1.88it/s]\rDownloading result files:  89%|████████▊ | 131/148 [01:08&lt;00:08,  1.89it/s]\rDownloading result files:  89%|████████▉ | 132/148 [01:08&lt;00:08,  1.89it/s]\rDownloading result files:  90%|████████▉ | 133/148 [01:09&lt;00:08,  1.77it/s]\rDownloading result files:  91%|█████████ | 134/148 [01:09&lt;00:07,  1.84it/s]\rDownloading result files:  91%|█████████ | 135/148 [01:10&lt;00:06,  1.86it/s]\rDownloading result files:  92%|█████████▏| 136/148 [01:10&lt;00:06,  1.95it/s]\rDownloading result files:  93%|█████████▎| 137/148 [01:11&lt;00:06,  1.80it/s]\rDownloading result files:  93%|█████████▎| 138/148 [01:12&lt;00:05,  1.81it/s]\rDownloading result files:  94%|█████████▍| 139/148 [01:12&lt;00:04,  1.89it/s]\rDownloading result files:  95%|█████████▍| 140/148 [01:13&lt;00:04,  1.91it/s]\rDownloading result files:  95%|█████████▌| 141/148 [01:13&lt;00:03,  1.97it/s]\rDownloading result files:  96%|█████████▌| 142/148 [01:13&lt;00:03,  1.98it/s]\rDownloading result files:  97%|█████████▋| 143/148 [01:14&lt;00:02,  1.94it/s]\rDownloading result files:  97%|█████████▋| 144/148 [01:15&lt;00:02,  1.97it/s]\rDownloading result files:  98%|█████████▊| 145/148 [01:15&lt;00:01,  1.91it/s]\rDownloading result files:  99%|█████████▊| 146/148 [01:16&lt;00:01,  1.79it/s]\rDownloading result files:  99%|█████████▉| 147/148 [01:16&lt;00:00,  1.88it/s]\rDownloading result files: 100%|██████████| 148/148 [01:17&lt;00:00,  1.92it/s]\rDownloading result files: 100%|██████████| 148/148 [01:17&lt;00:00,  1.92it/s]\n2022-04-20 05:02:43.535 | INFO     | feathr._databricks_submission:download_result:272 - Finish downloading files from dbfs:/feathrazure_test.parquet to /tmp/tmpg15bz4el.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_res"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9be042e-eb12-46b9-9d91-a0e5dd0c704f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[19]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n      <th>f_is_long_trip_distance</th>\n      <th>f_location_total_fare_cents</th>\n      <th>f_location_avg_fare</th>\n      <th>f_trip_distance_rounded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24650</td>\n      <td>None</td>\n      <td>2020-04-01 09:42:00</td>\n      <td>2020-04-01 09:52:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>121</td>\n      <td>73</td>\n      <td>None</td>\n      <td>2.12</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>8.3</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>800.0</td>\n      <td>8.000000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4123</td>\n      <td>2.0</td>\n      <td>2020-04-04 20:14:06</td>\n      <td>2020-04-04 20:34:30</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>260</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>7.13</td>\n      <td>23.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>24.8</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>3150.0</td>\n      <td>15.750000</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26545</td>\n      <td>None</td>\n      <td>2020-04-07 09:15:00</td>\n      <td>2020-04-07 09:32:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>28</td>\n      <td>73</td>\n      <td>None</td>\n      <td>3.9</td>\n      <td>15.24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>15.54</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>4674.0</td>\n      <td>15.579999</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7259</td>\n      <td>2.0</td>\n      <td>2020-04-09 01:01:59</td>\n      <td>2020-04-09 01:16:36</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>92</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>1.82</td>\n      <td>11.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>12.8</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>5824.0</td>\n      <td>14.559999</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12532</td>\n      <td>2.0</td>\n      <td>2020-04-16 01:22:45</td>\n      <td>2020-04-16 01:30:33</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>92</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>2.18</td>\n      <td>8.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>1.96</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>11.76</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>6674.0</td>\n      <td>13.348000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35607</th>\n      <td>33897</td>\n      <td>None</td>\n      <td>2020-04-28 16:27:00</td>\n      <td>2020-04-28 17:01:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>29</td>\n      <td>219</td>\n      <td>None</td>\n      <td>15.28</td>\n      <td>44.54</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>44.84</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>252801.0</td>\n      <td>35.605774</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>35608</th>\n      <td>34240</td>\n      <td>None</td>\n      <td>2020-04-29 07:00:00</td>\n      <td>2020-04-29 07:09:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>130</td>\n      <td>219</td>\n      <td>None</td>\n      <td>5.07</td>\n      <td>13.77</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>16.82</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>254178.0</td>\n      <td>35.302502</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>35609</th>\n      <td>34521</td>\n      <td>None</td>\n      <td>2020-04-29 15:59:00</td>\n      <td>2020-04-29 16:32:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>197</td>\n      <td>219</td>\n      <td>None</td>\n      <td>15.04</td>\n      <td>22.42</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>25.47</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>256420.0</td>\n      <td>35.126026</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>35610</th>\n      <td>35156</td>\n      <td>None</td>\n      <td>2020-04-30 13:13:00</td>\n      <td>2020-04-30 13:48:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>228</td>\n      <td>219</td>\n      <td>None</td>\n      <td>23.15</td>\n      <td>45.55</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>48.6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>260975.0</td>\n      <td>35.266891</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>35611</th>\n      <td>35459</td>\n      <td>None</td>\n      <td>2020-04-30 18:17:00</td>\n      <td>2020-04-30 18:25:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>222</td>\n      <td>219</td>\n      <td>None</td>\n      <td>5.65</td>\n      <td>37.46</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>40.51</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>264721.0</td>\n      <td>35.296131</td>\n      <td>56</td>\n    </tr>\n  </tbody>\n</table>\n<p>35612 rows × 25 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n      <th>f_is_long_trip_distance</th>\n      <th>f_location_total_fare_cents</th>\n      <th>f_location_avg_fare</th>\n      <th>f_trip_distance_rounded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24650</td>\n      <td>None</td>\n      <td>2020-04-01 09:42:00</td>\n      <td>2020-04-01 09:52:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>121</td>\n      <td>73</td>\n      <td>None</td>\n      <td>2.12</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>8.3</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>800.0</td>\n      <td>8.000000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4123</td>\n      <td>2.0</td>\n      <td>2020-04-04 20:14:06</td>\n      <td>2020-04-04 20:34:30</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>260</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>7.13</td>\n      <td>23.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>24.8</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>3150.0</td>\n      <td>15.750000</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26545</td>\n      <td>None</td>\n      <td>2020-04-07 09:15:00</td>\n      <td>2020-04-07 09:32:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>28</td>\n      <td>73</td>\n      <td>None</td>\n      <td>3.9</td>\n      <td>15.24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>15.54</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>4674.0</td>\n      <td>15.579999</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7259</td>\n      <td>2.0</td>\n      <td>2020-04-09 01:01:59</td>\n      <td>2020-04-09 01:16:36</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>92</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>1.82</td>\n      <td>11.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>12.8</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>5824.0</td>\n      <td>14.559999</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12532</td>\n      <td>2.0</td>\n      <td>2020-04-16 01:22:45</td>\n      <td>2020-04-16 01:30:33</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>92</td>\n      <td>73</td>\n      <td>1.0</td>\n      <td>2.18</td>\n      <td>8.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>1.96</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>11.76</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>6674.0</td>\n      <td>13.348000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35607</th>\n      <td>33897</td>\n      <td>None</td>\n      <td>2020-04-28 16:27:00</td>\n      <td>2020-04-28 17:01:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>29</td>\n      <td>219</td>\n      <td>None</td>\n      <td>15.28</td>\n      <td>44.54</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>44.84</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>252801.0</td>\n      <td>35.605774</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>35608</th>\n      <td>34240</td>\n      <td>None</td>\n      <td>2020-04-29 07:00:00</td>\n      <td>2020-04-29 07:09:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>130</td>\n      <td>219</td>\n      <td>None</td>\n      <td>5.07</td>\n      <td>13.77</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>16.82</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>254178.0</td>\n      <td>35.302502</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>35609</th>\n      <td>34521</td>\n      <td>None</td>\n      <td>2020-04-29 15:59:00</td>\n      <td>2020-04-29 16:32:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>197</td>\n      <td>219</td>\n      <td>None</td>\n      <td>15.04</td>\n      <td>22.42</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>25.47</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>256420.0</td>\n      <td>35.126026</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>35610</th>\n      <td>35156</td>\n      <td>None</td>\n      <td>2020-04-30 13:13:00</td>\n      <td>2020-04-30 13:48:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>228</td>\n      <td>219</td>\n      <td>None</td>\n      <td>23.15</td>\n      <td>45.55</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>48.6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>260975.0</td>\n      <td>35.266891</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>35611</th>\n      <td>35459</td>\n      <td>None</td>\n      <td>2020-04-30 18:17:00</td>\n      <td>2020-04-30 18:25:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>222</td>\n      <td>219</td>\n      <td>None</td>\n      <td>5.65</td>\n      <td>37.46</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.3</td>\n      <td>40.51</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>264721.0</td>\n      <td>35.296131</td>\n      <td>56</td>\n    </tr>\n  </tbody>\n</table>\n<p>35612 rows × 25 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Train a machine learning model\nAfter getting all the features, let's train a machine learning model with the converted feature by Feathr:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcbf17fc-7f79-4a65-a3af-9cffbd0b5d1f"}}},{"cell_type":"code","source":["# remove columns\nfrom sklearn.ensemble import GradientBoostingRegressor\nfinal_df = df_res\nfinal_df.drop([\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\",\n              \"store_and_fwd_flag\"], axis=1, inplace=True, errors='ignore')\nfinal_df.fillna(0, inplace=True)\nfinal_df['fare_amount'] = final_df['fare_amount'].astype(\"float64\")\n\n\ntrain_x, test_x, train_y, test_y = train_test_split(final_df.drop([\"fare_amount\"], axis=1),\n                                                    final_df[\"fare_amount\"],\n                                                    test_size=0.2,\n                                                    random_state=42)\nmodel = GradientBoostingRegressor()\nmodel.fit(train_x, train_y)\n\ny_predict = model.predict(test_x)\n\ny_actual = test_y.values.flatten().tolist()\nrmse = sqrt(mean_squared_error(y_actual, y_predict))\n\nsum_actuals = sum_errors = 0\n\nfor actual_val, predict_val in zip(y_actual, y_predict):\n    abs_error = actual_val - predict_val\n    if abs_error < 0:\n        abs_error = abs_error * -1\n\n    sum_errors = sum_errors + abs_error\n    sum_actuals = sum_actuals + actual_val\n\nmean_abs_percent_error = sum_errors / sum_actuals\nprint(\"Model MAPE:\")\nprint(mean_abs_percent_error)\nprint()\nprint(\"Model Accuracy:\")\nprint(1 - mean_abs_percent_error)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84745f36-5bac-49c0-903b-38828b923c7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Model MAPE:\n0.02640633467797197\n\nModel Accuracy:\n0.9735936653220281\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model MAPE:\n0.02640633467797197\n\nModel Accuracy:\n0.9735936653220281\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Materialize feature value into offline/online storage\n\nWhile Feathr can compute the feature value from the feature definition on-the-fly at request time, it can also pre-compute\nand materialize the feature value to offline and/or online storage. \n\nWe can push the generated features to the online store like below:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a226026-1c7b-48db-8f91-88d5c2ddf023"}}},{"cell_type":"code","source":["backfill_time = BackfillTime(start=datetime(\n    2020, 5, 20), end=datetime(2020, 5, 20), step=timedelta(days=1))\nredisSink = RedisSink(table_name=\"nycTaxiDemoFeature\")\nsettings = MaterializationSettings(\"nycTaxiTable\",\n                                   backfill_time=backfill_time,\n                                   sinks=[redisSink],\n                                   feature_names=[\"f_location_avg_fare\", \"f_location_max_fare\"])\n\nclient.materialize_features(settings)\nclient.wait_job_to_finish(timeout_sec=500)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b924c66-8634-42fe-90f3-c844487d3f75"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can then get the features from the online store (Redis):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a3e2ab1-5c66-4d27-a737-c5e2af03b1dd"}}},{"cell_type":"markdown","source":["## Fetching feature value for online inference\n\nFor features that are already materialized by the previous step, their latest value can be queried via the client's\n`get_online_features` or `multi_get_online_features` API."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bef93538-9591-4247-97b6-289d2055b7b1"}}},{"cell_type":"code","source":["res = client.get_online_features('nycTaxiDemoFeature', '265', [\n                                 'f_location_avg_fare', 'f_location_max_fare'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c3d5f35-11a3-4644-9992-5860169d8302"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["client.multi_get_online_features(\"nycTaxiDemoFeature\", [\"239\", \"265\"], [\n                                 'f_location_avg_fare', 'f_location_max_fare'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d4699ed-42e6-408f-903d-2f799284f4b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"interpreter":{"hash":"830c16c5b424e7ff512f67d4056b67cea1a756a7ad6a92c98b9e2b95c5e484ae"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.9.5","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"nyc_driver_demo","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":930353059183053}},"nbformat":4,"nbformat_minor":0}
